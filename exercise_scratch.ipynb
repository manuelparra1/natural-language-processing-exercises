{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5bd42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfae43cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/dusts/nltk_data...\r\n"
     ]
    }
   ],
   "source": [
    "# We don't need to install nltk, it should come with anaconda, but nltk\n",
    "# does need to download some data.\n",
    "!python -c \"import nltk; nltk.download('wordnet')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6773e599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/dusts/nltk_data...\r\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import nltk; nltk.download('omw-1.4')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb2561b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = acquire.get_blog_articles(acquire.get_codeup_links())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b188823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBlack excellence in tech: Panelist Spotlight – Wilmarie De La Cruz Mejia\\n\\nCodeup is hosting a Black Excellence in Tech Panel in honor of Black History Month on February 22, 2023! To further celebrate, we’d like to spotlight each of our panelists leading up to the discussion to learn a bit about their respective experiences as black leaders in the tech industry!\\xa0\\xa0\\nMeet Wilmarie!\\nWilmarie De\\xa0La Cruz Mejia is a current Codeup student on the path to becoming a Full-Stack Web Developer at our Dallas, TX campus.\\xa0\\nWilmarie is a veteran expanding her knowledge of programming languages and technologies on her journey with Codeup.\\xa0\\nWe asked Wilmarie to share more about her experience at Codeup. She shares, “I was able to meet other people who were passionate about coding and be in a positive learning environment.”\\nWe hope you can join us on February 22nd to sit in on an insightful conversation with Wilmarie and all of our panelists!\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles[0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "256b1231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black excellence in tech: Panelist Spotlight – Wilmarie De La Cruz Mejia\n",
      "\n",
      "Codeup is hosting a Black Excellence in Tech Panel in honor of Black History Month on February 22, 2023! To further celebrate, we’d like to spotlight each of our panelists leading up to the discussion to learn a bit about their respective experiences as black leaders in the tech industry!  \n",
      "Meet Wilmarie!\n",
      "Wilmarie De La Cruz Mejia is a current Codeup student on the path to becoming a Full-Stack Web Developer at our Dallas\n"
     ]
    }
   ],
   "source": [
    "original = all_articles[0]['content']\n",
    "print(original[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5897c6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "black excellence in tech: panelist spotlight – wilmarie de la cruz mejia\n",
      "\n",
      "codeup is hosting a black excellence in tech panel in honor of black history month on february 22, 2023! to further celebrate, we’d like to spotlight each of our panelists leading up to the discussion to learn a bit about their respective experiences as black leaders in the tech industry!  \n",
      "meet wilmarie!\n",
      "wilmarie de la cruz mejia is a current codeup student on the path to becoming a full-stack web developer at our dallas\n"
     ]
    }
   ],
   "source": [
    "article = original.lower()\n",
    "print(article[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "849d80b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "black excellence in tech: panelist spotlight  wilmarie de la cruz mejia\n",
      "\n",
      "codeup is hosting a black excellence in tech panel in honor of black history month on february 22, 2023! to further celebrate, wed like to spotlight each of our panelists leading up to the discussion to learn a bit about their respective experiences as black leaders in the tech industry!  \n",
      "meet wilmarie!\n",
      "wilmarie de la cruz mejia is a current codeup student on the path to becoming a full-stack web developer at our dallas, \n"
     ]
    }
   ],
   "source": [
    "article = unicodedata.normalize('NFKD', article)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "\n",
    "print(article[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "109d5490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "black excellence in tech panelist spotlight  wilmarie de la cruz mejia\n",
      "\n",
      "codeup is hosting a black excellence in tech panel in honor of black history month on february 22 2023 to further celebrate wed like to spotlight each of our panelists leading up to the discussion to learn a bit about their respective experiences as black leaders in the tech industry  \n",
      "meet wilmarie\n",
      "wilmarie de la cruz mejia is a current codeup student on the path to becoming a fullstack web developer at our dallas tx campus \n",
      "wilmarie is a veteran expanding her knowledge of programming languages and technologies on her journey with codeup \n",
      "we asked wilmarie to share more about her experience at codeup she shares i was able to meet other people who were passionate about coding and be in a positive learning environment\n",
      "we hope you can join us on february 22nd to sit in on an insightful conversation with wilmarie and all of our panelists\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#special characters\n",
    "# remove anything that is not a through z, a number, a single quote, or whitespace\n",
    "article = re.sub(r\"[^a-z0-9'\\s]\", '', article)\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a3ee28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black excellence in tech panelist spotlight wilmarie de la cruz mejia\n",
      "\n",
      "codeup is hosting a black excellence in tech panel in honor of black history month on february 22 2023 to further celebrate wed like to spotlight each of our panelists leading up to the discussion to learn a bit about their respective experiences as black leaders in the tech industry \n",
      "meet wilmarie\n",
      "wilmarie de la cruz mejia is a current codeup student on the path to becoming a fullstack web developer at our dallas tx campus \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tokenize\n",
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "print(tokenizer.tokenize(article, return_str=True)[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a35597f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('call', 'call', 'call')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the nltk stemmer object, then use it\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "ps.stem('call'), ps.stem('called'), ps.stem('calling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "922b194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black excel in tech panelist spotlight wilmari de la cruz mejia codeup is host a black excel in tech panel in honor of black histori month on februari 22 2023 to further celebr wed like to spotlight each of our panelist lead up to the discuss to learn a bit about their respect experi as black leader in the tech industri meet wilmari wilmari de la cruz mejia is a current codeup student on the path to becom a fullstack web develop at our dalla tx campu wilmari is a veteran expand her knowledg of program languag and technolog on her journey with codeup we ask wilmari to share more about her experi at codeup she share i wa abl to meet other peopl who were passion about code and be in a posit learn environ we hope you can join us on februari 22nd to sit in on an insight convers with wilmari and all of our panelist\n"
     ]
    }
   ],
   "source": [
    "stems = [ps.stem(word) for word in article.split()]\n",
    "article_stemmed = ' '.join(stems)\n",
    "print(article_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9354da22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to         8\n",
       "a          6\n",
       "in         6\n",
       "wilmari    6\n",
       "on         5\n",
       "black      4\n",
       "of         4\n",
       "codeup     4\n",
       "and        3\n",
       "about      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(stems).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e5aaf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem: he -- lemma: He\n",
      "stem: wa -- lemma: wa\n",
      "stem: run -- lemma: running\n",
      "stem: and -- lemma: and\n",
      "stem: eat -- lemma: eating\n",
      "stem: at -- lemma: at\n",
      "stem: same -- lemma: same\n",
      "stem: time. -- lemma: time.\n",
      "stem: he -- lemma: He\n",
      "stem: ha -- lemma: ha\n",
      "stem: bad -- lemma: bad\n",
      "stem: habit -- lemma: habit\n",
      "stem: of -- lemma: of\n",
      "stem: swim -- lemma: swimming\n",
      "stem: after -- lemma: after\n",
      "stem: play -- lemma: playing\n",
      "stem: long -- lemma: long\n",
      "stem: hour -- lemma: hour\n",
      "stem: in -- lemma: in\n",
      "stem: the -- lemma: the\n",
      "stem: sun. -- lemma: Sun.\n"
     ]
    }
   ],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "\n",
    "for word in sentence.split():\n",
    "    print('stem:', ps.stem(word), '-- lemma:', wnl.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "243f26d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black excellence in tech panelist spotlight wilmarie de la cruz mejia codeup is hosting a black excellence in tech panel in honor of black history month on february 22 2023 to further celebrate wed like to spotlight each of our panelist leading up to the discussion to learn a bit about their respective experience a black leader in the tech industry meet wilmarie wilmarie de la cruz mejia is a current codeup student on the path to becoming a fullstack web developer at our dallas tx campus wilmarie is a veteran expanding her knowledge of programming language and technology on her journey with codeup we asked wilmarie to share more about her experience at codeup she share i wa able to meet other people who were passionate about coding and be in a positive learning environment we hope you can join u on february 22nd to sit in on an insightful conversation with wilmarie and all of our panelist\n"
     ]
    }
   ],
   "source": [
    "#lemmatize\n",
    "lemmas = [wnl.lemmatize(word) for word in article.split()]\n",
    "article_lemmatized = ' '.join(lemmas)\n",
    "\n",
    "print(article_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05a4a3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to          8\n",
       "a           7\n",
       "in          6\n",
       "wilmarie    6\n",
       "on          5\n",
       "codeup      4\n",
       "of          4\n",
       "black       4\n",
       "the         3\n",
       "our         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lemmas).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60706fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "stopword_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "170389be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 70 stopwords\n",
      "---\n",
      "black excellence tech panelist spotlight wilmarie de la cruz mejia codeup hosting black excellence tech panel honor black history month february 22 2023 celebrate wed like spotlight panelists leading discussion learn bit respective experiences black leaders tech industry meet wilmarie wilmarie de la cruz mejia current codeup student path becoming fullstack web developer dallas tx campus wilmarie veteran expanding knowledge programming languages technologies journey codeup asked wilmarie share experience codeup shares able meet people passionate coding positive learning environment hope join us february 22nd sit insightful conversation wilmarie panelists\n"
     ]
    }
   ],
   "source": [
    "words = article.split()\n",
    "filtered_words = [w for w in words if w not in stopword_list]\n",
    "\n",
    "print('Removed {} stopwords'.format(len(words) - len(filtered_words)))\n",
    "print('---')\n",
    "\n",
    "article_without_stopwords = ' '.join(filtered_words)\n",
    "\n",
    "print(article_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8dc3a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stopwords = article_without_stopwords.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8a618211",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_series = pd.Series(no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee67ea1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            black\n",
       "1       excellence\n",
       "2             tech\n",
       "3         panelist\n",
       "4        spotlight\n",
       "          ...     \n",
       "84             sit\n",
       "85      insightful\n",
       "86    conversation\n",
       "87        wilmarie\n",
       "88       panelists\n",
       "Length: 89, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e43157e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wilmarie      6\n",
       "black         4\n",
       "codeup        4\n",
       "tech          3\n",
       "meet          2\n",
       "excellence    2\n",
       "mejia         2\n",
       "cruz          2\n",
       "la            2\n",
       "de            2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_series.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55cca08",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c86a16c",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "#### The end result of this exercise should be a file named `prepare.py` that defines the requested functions.\n",
    "\n",
    "#### In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3d1f3",
   "metadata": {},
   "source": [
    "### 1. Define a function named `basic_clean`. It should take in a string and apply some basic text cleaning to it:\n",
    "#### - Lowercase everything\n",
    "#### - Normalize unicode characters\n",
    "#### - Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(text):\n",
    "    '''\n",
    "        This function cleans a string of text\n",
    "        and returns the cleaned string.\n",
    "        \n",
    "    '''\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # normalize unicode characters\n",
    "    text = unicodedata.normalize('NFKD', text)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "    \n",
    "    # only alphanumeric, apostrophe, & Spaces\n",
    "    text = re.sub(r\"[^a-z0-9'\\s]\", '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3ece60",
   "metadata": {},
   "source": [
    "### 2. Define a function named `tokenize`. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf42403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a040f",
   "metadata": {},
   "source": [
    "### 3. Define a function named `stem`. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3947452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4feff2",
   "metadata": {},
   "source": [
    "### 4. Define a function named `lemmatize`. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb28d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6475f159",
   "metadata": {},
   "source": [
    "### 5. Define a function named `remove_stopwords`. It should accept some text and return the text after removing all the stopwords.\n",
    "#### This function should define two optional parameters, `extra_words` and `exclude_words`. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9611dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text,extra_words=None,exclude_words=None):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16db1283",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = \n",
    "originals = \n",
    "cleaned = \n",
    "stemmed = \n",
    "lemmatized = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa67446c",
   "metadata": {},
   "source": [
    "### 6. Use your data from the `acquire` to produce a dataframe of the news articles. Name the dataframe `news_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame({\"title\":titles,\"original\":originals,\"clean\":cleaned,\"stemmed\":stemmed,\"lemmatized\":lemmatized})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac54eb53",
   "metadata": {},
   "source": [
    "### 7. Make another dataframe for the Codeup blog posts. Name the dataframe `codeup_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df = pd.DataFrame({\"title\":titles,\"original\":originals,\"clean\":cleaned,\"stemmed\":stemmed,\"lemmatized\":lemmatized})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580aad0d",
   "metadata": {},
   "source": [
    "### 8. For each dataframe, produce the following columns:\n",
    "#### - `title` to hold the title\n",
    "#### - `original` to hold the original article/post content\n",
    "#### - `clean` to hold the normalized and tokenized original with the stopwords removed.\n",
    "#### - `stemmed` to hold the stemmed version of the cleaned data.\n",
    "#### - `lemmatized` to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa06593",
   "metadata": {},
   "source": [
    "### 9. Ask yourself:\n",
    "#### - If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "#### - If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "#### - If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46f6b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d88660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "- lemmatized\n",
    "- stemmed\n",
    "- stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1b0796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string\n",
    "    and returns the string as individual tokens put back into the string\n",
    "    '''\n",
    "    #create the tokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "    #use the tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str = True)\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23bb458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in text\n",
    "    and returns the stem word joined back into the text\n",
    "    '''\n",
    "    #create porter stemmer\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    #use the stem, split string using each word\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    \n",
    "    #join stem word to string\n",
    "    string = ' '.join(stems)\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f275a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in a string\n",
    "    and returns the lemmatized word joined back into the string\n",
    "    '''\n",
    "    #create the lemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    #look at the article \n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    #join lemmatized words into article\n",
    "    string = ' '.join(lemmas)\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f9a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in text, extra words and exclude words\n",
    "    and returns a list of text with stopword removed\n",
    "    '''\n",
    "    #create stopword list\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    #remove excluded words from list\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    \n",
    "    #add the extra words to the list\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    \n",
    "    #split the string into different words\n",
    "    words = string.split()\n",
    "    \n",
    "    #create a list of words that are not in the list\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    #join the words that are not stopwords (filtered words) back into the string\n",
    "    string = ' '.join(filtered_words)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_article_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function take in a df and the string name for a text column with \n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    #original text from content column\n",
    "    df['original'] = df['content']\n",
    "    \n",
    "    #chain together clean, tokenize, remove stopwords\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    #chain clean, tokenize, stem, remove stopwords\n",
    "    df['stemmed'] = df['clean'].apply(stem)\n",
    "    \n",
    "    #clean clean, tokenize, lemmatize, remove stopwords\n",
    "    df['lemmatized'] = df['clean'].apply(lemmatize)\n",
    "    \n",
    "    return df[['title', 'original', 'clean', 'stemmed', 'lemmatized']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
